{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Import necessary packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib.patches import Ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILES = ['classificationA.train', 'classificationA.test',\n",
    "         'classificationB.train', 'classificationB.test',\n",
    "         'classificationC.train', 'classificationC.test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONFIG = {'A': {'DS': 'A', 'TRAIN': FILES[0], 'TEST': FILES[1]},\n",
    "          'B': {'DS': 'B', 'TRAIN': FILES[2], 'TEST': FILES[3]},\n",
    "          'C': {'DS': 'C', 'TRAIN': FILES[4], 'TEST': FILES[5]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CONFIG = CONFIG['A']  # Chose which dataset you want to run the analysis on\n",
    "STOPPING = 0.001  # stopping criterion for IRLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize tensorflow variables\n",
    "test = tf.placeholder(dtype=tf.float32, shape=[None, 3,])\n",
    "train = tf.placeholder(dtype=tf.float32, shape=[None, 3,])\n",
    "pi_mle = tf.Variable(initial_value=0, dtype=tf.float32)\n",
    "mu_0_mle = tf.Variable(initial_value=[0,0], dtype=tf.float32)\n",
    "mu_1_mle = tf.Variable(initial_value=[0,0], dtype=tf.float32)\n",
    "sigma_mle = tf.Variable(initial_value=[[0,0], [0,0]], dtype=tf.float32)\n",
    "sigma_mle_1 = tf.Variable(initial_value=[[0,0], [0,0]], dtype=tf.float32)\n",
    "sigma_mle_2 = tf.Variable(initial_value=[[0,0], [0,0]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Compute pi MLE for MoG\n",
    "pi_mle = pi_mle.assign(tf.reduce_mean(train, axis=0)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Compute mu MLE for MoG\n",
    "group_1 = tf.squeeze(tf.gather(train[:,0:2], indices=tf.where(condition=tf.equal(train[:, 2],0))))\n",
    "mu_0_mle = mu_0_mle.assign(tf.reduce_mean(group_1, axis=0))\n",
    "group_2 = tf.squeeze(tf.gather(train[:,0:2], indices=tf.where(condition=tf.equal(train[:, 2],1))))\n",
    "mu_1_mle = mu_1_mle.assign(tf.reduce_mean(group_2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Compute Sigma MLE for MoG\n",
    "size_1 = tf.cast(tf.shape(group_1)[0], tf.float32)\n",
    "sigma_mle_1 = sigma_mle_1.assign(tf.matmul(tf.transpose(group_1), group_1)/size_1)\n",
    "sigma_mle_1 -= [[mu_0_mle[0]**2, mu_0_mle[0]*mu_0_mle[1]],\n",
    "                 [mu_0_mle[0]*mu_0_mle[1], mu_0_mle[1]**2]]\n",
    "size_2 = tf.cast(tf.shape(group_2)[0], tf.float32)\n",
    "sigma_mle_2 = sigma_mle_2.assign(tf.matmul(tf.transpose(group_2), group_2)/size_2)\n",
    "sigma_mle_2 -= [[mu_1_mle[0]**2, mu_1_mle[0]*mu_1_mle[1]],\n",
    "                 [mu_1_mle[0]*mu_1_mle[1], mu_1_mle[1]**2]]\n",
    "sigma_mle = sigma_mle.assign((size_1/(size_1+size_2))*sigma_mle_1 + (size_1/(size_1+size_2))*sigma_mle_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Logistic Regression OPs\n",
    "train_labels = tf.placeholder(dtype=tf.float32, shape=[None, 1,])\n",
    "logistic_weights = tf.Variable(initial_value=tf.random_uniform(shape=[3, 1]), dtype=tf.float32)\n",
    "\n",
    "mu = tf.sigmoid(tf.matmul(train, logistic_weights))\n",
    "D = tf.diag(tf.squeeze(tf.add(1.0, -mu)))\n",
    "logistic_update = tf.matrix_inverse(tf.matmul(tf.matmul(tf.transpose(train), D), train))\n",
    "logistic_update = tf.matmul(tf.matmul(logistic_update, tf.transpose(train)), tf.add(mu, -train_labels))\n",
    "logistic_train_op = logistic_weights.assign(tf.add(logistic_weights,-logistic_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Linear Regression OPs\n",
    "linear_weights = tf.Variable(initial_value=tf.random_uniform(shape=[3, 1]), dtype=tf.float32)\n",
    "linear_train_op = linear_weights.assign(\n",
    "    tf.matmul(\n",
    "        tf.matmul(tf.matrix_inverse(tf.matmul(tf.transpose(train), train)), tf.transpose(train)),\n",
    "        train_labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Do computations in Tensorflow!\n",
    "with tf.Session() as sess:\n",
    "    train_data = pd.read_table('hwk2data/' + CONFIG['TRAIN'], header=None)\n",
    "    test_data = pd.read_table('hwk2data/' + CONFIG['TEST'], header=None)\n",
    "    sess.run(init_op)\n",
    "\n",
    "    #  Q1 TF comps\n",
    "    pi_mle, mu_0_mle, mu_1_mle, \\\n",
    "    sigma_mle, sigma_mle_1, sigma_mle_2 = sess.run([pi_mle, mu_0_mle, mu_1_mle, sigma_mle, sigma_mle_1, sigma_mle_2],\n",
    "                                                   feed_dict={train: train_data, test: test_data})\n",
    "\n",
    "    #  Q2 TF comps\n",
    "    train_data[3] = [1] * train_data.shape[0]\n",
    "\n",
    "    logistic_weights = sess.run(logistic_train_op, feed_dict={train: train_data[[0, 1, 3]],\n",
    "                                                              train_labels: train_data[[2]]})\n",
    "    previous_weights = np.array([0, 0, 0])\n",
    "\n",
    "    step = 1\n",
    "    while np.linalg.norm(logistic_weights.flatten()-previous_weights) > STOPPING:  # Stopping criterion\n",
    "        previous_weights = logistic_weights.flatten()\n",
    "        logistic_weights = sess.run(logistic_train_op, feed_dict={train: train_data[[0, 1, 3]],\n",
    "                                                                  train_labels: train_data[[2]]})\n",
    "        #print('Updating weights for separating plane, step {} ...'.format(step))\n",
    "        step += 1\n",
    "        #print('Norm of change in weights ...')\n",
    "        #print(np.linalg.norm(logistic_weights.flatten()-previous_weights))\n",
    "\n",
    "    #  Q3 TF comps\n",
    "    linear_weights = sess.run(linear_train_op, feed_dict={train: train_data[[0, 1, 3]],\n",
    "                                                          train_labels: train_data[[2]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################\n",
    "#################### Question 1 C #######################\n",
    "#########################################################\n",
    "\n",
    "#  Implementing MLE for Mixture of Gaussians with shared Covariance to each Dataset.\n",
    "\n",
    "#  Compute seperating plane\n",
    "m_0 = -np.dot(np.transpose(mu_0_mle), np.linalg.inv(sigma_mle))\n",
    "m_1 = -np.dot(np.transpose(mu_1_mle), np.linalg.inv(sigma_mle))\n",
    "b_0 = -0.5*np.dot(m_0, mu_0_mle) + np.log(1-pi_mle)\n",
    "b_1 = -0.5*np.dot(m_1, mu_1_mle) + np.log(pi_mle)\n",
    "print(\"Weights for LDA seperating line: \",(m_0-m_1)[0],(m_0-m_1)[1], b_0-b_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def line(x):\n",
    "    return -(b_0-b_1 + (m_0[0]-m_1[0])*x)/(m_0[1]-m_1[1])\n",
    "\n",
    "#  Plot data points\n",
    "plt.figure()\n",
    "plt.scatter(x=train_data[train_data[2] == 0][0], y=train_data[train_data[2] == 0][1], color='red')\n",
    "plt.scatter(x=train_data[train_data[2] == 1][0], y=train_data[train_data[2] == 1][1], color='blue')\n",
    "\n",
    "#  Overlay with contours of Normal Dist.\n",
    "x = np.linspace(-8, 8)\n",
    "y = np.linspace(-8, 8)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z1 = mlab.bivariate_normal(X, Y, sigmax=sigma_mle[0,0], sigmay=sigma_mle[1,1],\n",
    "                           mux=mu_0_mle[0], muy=mu_0_mle[1], sigmaxy=sigma_mle[1,0])\n",
    "Z2 = mlab.bivariate_normal(X, Y, sigmax=sigma_mle[0,0], sigmay=sigma_mle[1,1],\n",
    "                           mux=mu_1_mle[0], muy=mu_1_mle[1], sigmaxy=sigma_mle[1,0])\n",
    "plt.contour(X, Y, Z1, colors='pink')\n",
    "plt.contour(X, Y, Z2, colors='turquoise')\n",
    "\n",
    "x = np.linspace(-2, 2)\n",
    "plt.plot(x, line(x), 'k-', linewidth=1)\n",
    "plt.xlabel('Dim 1')\n",
    "plt.ylabel('Dim 2')\n",
    "plt.title('Dataset {}: Separating Plane - LDA'.format(CONFIG['DS']))\n",
    "#plt.savefig('../img_{}_MoG'.format(CONFIG['DS'])) # to save figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Compute error rate\n",
    "def get_error_rate(w_1,w_2, b, X_0, X_1, Y):\n",
    "    tp = np.logical_and(np.add(w_1*X_0, w_2*X_1) + b > 0, Y == 1)\n",
    "    tn = np.logical_and(np.add(w_1 * X_0, w_2 * X_1) + b < 0, Y == 0)\n",
    "    error_rate = 1 - (np.sum(tp)+np.sum(tn))/X_0.shape[0]\n",
    "    return(error_rate)\n",
    "\n",
    "train_rate = get_error_rate(w_1=(m_0 - m_1)[0], w_2=(m_0 - m_1)[1], b=(b_0-b_1),\n",
    "                            X_0=train_data[[0]], X_1=train_data[[1]], Y=train_data[[2]])\n",
    "print('MoG Training rate: {}'.format(round(train_rate[0],4)))\n",
    "\n",
    "test_rate = get_error_rate(w_1=(m_0 - m_1)[0], w_2=(m_0 - m_1)[1], b=(b_0-b_1),\n",
    "                           X_0=test_data[[0]], X_1=test_data[[1]], Y=test_data[[2]])\n",
    "print('MoG Testing rate: {}'.format(round(test_rate[0],4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#################### Question 2 #######################\n",
    "#######################################################\n",
    "\n",
    "#  Implementing Logistic Regression to each Dataset.\n",
    "print(\"Weights for Logistic Regression: \", logistic_weights.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def line(x):\n",
    "    return -(logistic_weights[2] + (logistic_weights[0])*x)/(logistic_weights[1])\n",
    "\n",
    "#  Plot data points and seperating plane\n",
    "plt.figure()\n",
    "plt.scatter(x=train_data[train_data[2] == 0][0], y=train_data[train_data[2] == 0][1], color='red')\n",
    "plt.scatter(x=train_data[train_data[2] == 1][0], y=train_data[train_data[2] == 1][1], color='blue')\n",
    "\n",
    "x = np.linspace(-3, 3)\n",
    "plt.plot(x, line(x), 'k-', linewidth=1)\n",
    "plt.xlabel('Dim 1')\n",
    "plt.ylabel('Dim 2')\n",
    "plt.title('Dataset {}: Separating Plane - Logistic'.format(CONFIG['DS']))\n",
    "\n",
    "#plt.savefig('../img_{}_Log'.format(CONFIG['DS']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_rate = get_error_rate(w_1=logistic_weights[0], w_2=logistic_weights[1], b=logistic_weights[2],\n",
    "                            X_0=train_data[[0]], X_1=train_data[[1]], Y=train_data[[2]])\n",
    "print('Logistic Training rate: {}'.format(round(train_rate[0],4)))\n",
    "\n",
    "test_rate = get_error_rate(w_1=logistic_weights[0], w_2=logistic_weights[1], b=logistic_weights[2],\n",
    "                           X_0=test_data[[0]], X_1=test_data[[1]], Y=test_data[[2]])\n",
    "print('Logistic Testing rate: {}'.format(round(test_rate[0],4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#################### Question 3 #######################\n",
    "#######################################################\n",
    "\n",
    "#  See Linear Regression weights for Dataset.\n",
    "print(\"Weights for Linear Regression: \", linear_weights.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def line(x):\n",
    "    return (0.5 - linear_weights[2] - (linear_weights[0])*x)/(linear_weights[1])\n",
    "\n",
    "#  Plot data points and seperating plane\n",
    "plt.figure()\n",
    "plt.scatter(x=train_data[train_data[2] == 0][0], y=train_data[train_data[2] == 0][1], color='red')\n",
    "plt.scatter(x=train_data[train_data[2] == 1][0], y=train_data[train_data[2] == 1][1], color='blue')\n",
    "\n",
    "x = np.linspace(-3, 3)\n",
    "plt.plot(x, line(x), 'k-', linewidth=1)\n",
    "plt.xlabel('Dim 1')\n",
    "plt.ylabel('Dim 2')\n",
    "plt.title('Dataset {}: Separating Plane - Linear'.format(CONFIG['DS']))\n",
    "\n",
    "#plt.savefig('../img_{}_Lin'.format(CONFIG['DS']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Compute error rate\n",
    "def get_error_rate(w_1,w_2, b, X_0, X_1, Y):\n",
    "    tp = np.logical_and(np.add(w_1*X_0, w_2*X_1) + b > 0.5, Y == 1)\n",
    "    tn = np.logical_and(np.add(w_1 * X_0, w_2 * X_1) + b < 0.5, Y == 0)\n",
    "    error_rate = 1 - ((np.sum(tp)+np.sum(tn))/X_0.shape[0])\n",
    "    return(error_rate)\n",
    "\n",
    "train_rate = get_error_rate(w_1=linear_weights[0], w_2=linear_weights[1], b=linear_weights[2],\n",
    "                            X_0=train_data[[0]], X_1=train_data[[1]], Y=train_data[[2]])\n",
    "print('LR Training rate: {}'.format(round(train_rate[0], 4)))\n",
    "\n",
    "test_rate = get_error_rate(w_1=linear_weights[0], w_2=linear_weights[1], b=linear_weights[2],\n",
    "                           X_0=test_data[[0]], X_1=test_data[[1]], Y=test_data[[2]])\n",
    "print('LR Testing rate: {}'.format(round(test_rate[0], 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#################### Question 5 #######################\n",
    "#######################################################\n",
    "\n",
    "#  Compute seperating plane\n",
    "s_mle_inv_1 = np.linalg.inv(sigma_mle_1)\n",
    "s_mle_inv_2 = np.linalg.inv(sigma_mle_2)\n",
    "b = 0.5*np.log(np.linalg.det(sigma_mle_2)/np.linalg.det(sigma_mle_1)) + np.log(pi_mle/(1-pi_mle)) \\\n",
    "    - 0.5*np.dot(np.dot(np.transpose(mu_0_mle), s_mle_inv_1),mu_0_mle) \\\n",
    "    + 0.5*np.dot(np.dot(np.transpose(mu_1_mle), s_mle_inv_2),mu_1_mle)\n",
    "\n",
    "m_x = np.dot(s_mle_inv_1, mu_0_mle)[0] - np.dot(s_mle_inv_2, mu_1_mle)[0]\n",
    "m_y = np.dot(s_mle_inv_1, mu_0_mle)[1] - np.dot(s_mle_inv_2, mu_1_mle)[1]\n",
    "\n",
    "m_x2 = -0.5*s_mle_inv_1[0,0] + 0.5*s_mle_inv_2[0,0]\n",
    "m_xy = -s_mle_inv_1[0,1] + s_mle_inv_2[0,1]\n",
    "m_y2 = -0.5*s_mle_inv_1[1,1] +0.5*s_mle_inv_2[1,1]\n",
    "\n",
    "print(\"Weights for QDA seperating line: \", m_x, m_y, m_x2, m_xy, m_y2, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Plot data points\n",
    "plt.figure()\n",
    "plt.scatter(x=train_data[train_data[2] == 0][0], y=train_data[train_data[2] == 0][1], color='red')\n",
    "plt.scatter(x=train_data[train_data[2] == 1][0], y=train_data[train_data[2] == 1][1], color='blue')\n",
    "\n",
    "#  Overlay with contours of Normal Dist.\n",
    "x = np.linspace(-8, 8)\n",
    "y = np.linspace(-8, 8)\n",
    "x, y = np.meshgrid(x, y)\n",
    "Z1 = mlab.bivariate_normal(X, Y, sigmax=sigma_mle_1[0,0], sigmay=sigma_mle_1[1,1],\n",
    "                           mux=mu_0_mle[0], muy=mu_0_mle[1], sigmaxy=sigma_mle_1[1,0])\n",
    "Z2 = mlab.bivariate_normal(X, Y, sigmax=sigma_mle_2[0,0], sigmay=sigma_mle_2[1,1],\n",
    "                           mux=mu_1_mle[0], muy=mu_1_mle[1], sigmaxy=sigma_mle_2[1,0])\n",
    "plt.contour(X, Y, Z1, colors='pink')\n",
    "plt.contour(X, Y, Z2, colors='turquoise')\n",
    "\n",
    "#  Plot seperating conic\n",
    "plt.contour(x, y, (x*m_x + y*m_y + m_x2*x**2 + m_xy*x*y + m_y2*y**2 + b), [0], colors='k')\n",
    "plt.xlabel('Dim 1')\n",
    "plt.ylabel('Dim 2')\n",
    "plt.title('Dataset {}: Separating Conic - QGA'.format(CONFIG['DS']))\n",
    "#plt.savefig('../img_{}_MoG_dm'.format(CONFIG['DS']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Print learned parameters\n",
    "print('The learned parameters are:')\n",
    "print('pi: {0} \\n mean 1: {1} \\n mean 2: {2} \\n Sigma 1: {3} \\n Sigma 2: {4}'\n",
    "      .format(pi_mle, mu_0_mle, mu_1_mle, sigma_mle_1, sigma_mle_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Compute error rate\n",
    "def get_error_rate(X_0, X_1, Y):\n",
    "    tp = np.logical_and(\n",
    "        np.add(np.add(np.add(np.add(np.add(X_0*m_x, X_1*m_y), m_x2*X_0**2),\n",
    "                             m_xy*np.multiply(X_0, X_1)), m_y2*X_1**2), b) < 0, Y == 1)\n",
    "    tn = np.logical_and(\n",
    "        np.add(np.add(np.add(np.add(np.add(X_0*m_x, X_1*m_y), m_x2*X_0**2),\n",
    "                             m_xy*np.multiply(X_0,X_1)), m_y2*X_1**2), b) > 0, Y == 0)\n",
    "    error_rate = 1 - ((np.sum(tp)+np.sum(tn))/X_0.shape[0])\n",
    "    return(error_rate)\n",
    "\n",
    "train_rate = get_error_rate(X_0=train_data[[0]], X_1=train_data[[1]], Y=train_data[[2]])\n",
    "print('QDA Training rate: {}'.format(round(train_rate[0],4)))\n",
    "\n",
    "test_rate = get_error_rate(X_0=test_data[[0]], X_1=test_data[[1]], Y=test_data[[2]])\n",
    "print('QDA Testing rate: {}'.format(round(test_rate[0],4)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:KerasEnv]",
   "language": "python",
   "name": "conda-env-KerasEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
